<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>2020-12-03_ConcreteXGB.utf8</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">[datadavidz]</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="blog.html">Blog</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="http://github.com/datadavidz">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>




</div>


<p><br></p>
<div id="extreme-gradient-boosting-modeling-of-the-concrete-compressive-strength-dataset" class="section level2">
<h2><strong>Extreme Gradient Boosting Modeling of the Concrete Compressive Strength Dataset</strong></h2>
<p><em>Posted on December 3, 2020</em></p>
<p>In this post, we will begin to use machine learning techniques for predicting compressive strength of formulations using the concrete dataset. In a previous post, we created a model using a conventional material modeling approach which resulted in an R<sup>2</sup> of 0.78. Here we will use an XGBoost model to predict compressive strength and compare the results with the conventional material model.</p>
<div id="stage-1-model-tuning" class="section level3">
<h3>Stage 1: Model Tuning</h3>
<p>Initial splitting of the dataset into Training and Test Dataset Here we use the rsample package to create an 80/20 split. The concrete dataset contains 1030 formulations of which 825 are randomly assigned to training and 205 are randomly assigned to testing.</p>
<pre class="r"><code>set.seed(123)
concrete_split &lt;- initial_split(concrete_tbl, prop = 0.80)
concrete_train &lt;- training(concrete_split)
concrete_test &lt;- testing(concrete_split)</code></pre>
<p>Preprocessing is accomplished by using the recipe package. The recipe provides the steps required to transform our raw data into a dataset suitable for machine learning. The Concrete dataset actually doesn’t require much reformatting. The major issue was the lengthy column names which was addressed immediately after the dataset was imported. The dataset contained all numerical values and no missing data. Initially we will just center and scale the predictors before sending to the nnet model.</p>
<pre class="r"><code>concrete_rec &lt;- recipe(compressive_strength ~ ., data = concrete_train) %&gt;%
  step_center(all_predictors()) %&gt;%
  step_scale(all_predictors())

concrete_rec</code></pre>
<pre><code>## Data Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          8
## 
## Operations:
## 
## Centering for all_predictors()
## Scaling for all_predictors()</code></pre>
<p>Cross validation folds are created in order to assess the performance of the model parameters. Here we use 5-fold cross validation to create splits from our training dataset and also using the preprocessing pipeline specified above.</p>
<pre class="r"><code>set.seed(234)
concrete_folds &lt;- vfold_cv(concrete_train, v = 5)

concrete_folds</code></pre>
<pre><code>## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits            id   
##   &lt;list&gt;            &lt;chr&gt;
## 1 &lt;split [660/165]&gt; Fold1
## 2 &lt;split [660/165]&gt; Fold2
## 3 &lt;split [660/165]&gt; Fold3
## 4 &lt;split [660/165]&gt; Fold4
## 5 &lt;split [660/165]&gt; Fold5</code></pre>
<p>Model specifications are created using the parsnip package. Here we specify a boosted tree model using the XGBoost engine. Notice that the min n, tree depth and learn rate parameters have been specified to be tuned.</p>
<pre class="r"><code>xgboost_spec = boost_tree(
  mode = &quot;regression&quot;,
  trees = 1000,
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune()
) %&gt;%
  set_engine(&quot;xgboost&quot;, objective = &quot;reg:squarederror&quot;) %&gt;%
  set_mode(&quot;regression&quot;)

xgboost_spec</code></pre>
<pre><code>## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   trees = 1000
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
## 
## Engine-Specific Arguments:
##   objective = reg:squarederror
## 
## Computational engine: xgboost</code></pre>
<pre class="r"><code>set.seed(345)
xgboost_grid &lt;- grid_max_entropy(min_n(), tree_depth(), learn_rate(), size = 30)

# xgboost_grid %&gt;%
#   ggplot(aes(penalty, hidden_units)) +
#   geom_point(color = &quot;steelblue&quot;, size = 3) +
#   scale_x_log10() +
#   theme_light() +
#   labs(title = &quot;Max Entropy Grid&quot;, x = &quot;Penalty (log scale)&quot;, y = &quot;Hidden Units&quot;)

xgboost_grid</code></pre>
<pre><code>## # A tibble: 30 x 3
##    min_n tree_depth learn_rate
##    &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;
##  1     6          1   8.78e- 7
##  2    38          3   9.89e- 8
##  3    30          1   1.18e- 2
##  4    23          5   3.77e- 7
##  5    37         15   1.07e-10
##  6    16          6   3.19e- 4
##  7    12          7   1.34e-10
##  8    40         10   9.93e- 8
##  9     2         15   2.08e- 8
## 10    36         10   2.64e- 2
## # ... with 20 more rows</code></pre>
<p>Define a workflow for the tuning process</p>
<pre class="r"><code>concrete_wf &lt;- workflow() %&gt;%
  add_recipe(concrete_rec) %&gt;%
  add_model(xgboost_spec)</code></pre>
<p>Hyperparameter tuning is now performed using the tune_grid() function from the tune package. Here we specific the formula, model, resamples, grid and metrics. The metrics come from the yardstick package. For regression problems, we can specify multiple metrics such as mae, mape, rmse and rsq into a metric_set().</p>
<pre class="r"><code>doParallel::registerDoParallel()

set.seed(456)

begin &lt;- Sys.time()

xgboost_res &lt;- tune_grid(
  concrete_wf,
  resamples = concrete_folds,
  grid = xgboost_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(save_pred = TRUE)
)

end1 &lt;- Sys.time() - begin</code></pre>
</div>
<div id="stage-2-compare-and-select-the-best-model" class="section level3">
<h3>Stage 2: Compare and Select the Best Model</h3>
<p>Identify the best hyperparameter values using the show_best() function.</p>
<pre class="r"><code>xgboost_res %&gt;% show_best(&quot;mae&quot;, n = 5)</code></pre>
<pre><code>## # A tibble: 5 x 9
##   min_n tree_depth learn_rate .metric .estimator  mean     n std_err .config
##   &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
## 1    18         10    0.0265  mae     standard    3.19     5   0.155 Model14
## 2    28          7    0.0302  mae     standard    3.23     5   0.144 Model30
## 3    36         10    0.0264  mae     standard    3.36     5   0.126 Model10
## 4    19          2    0.0904  mae     standard    3.38     5   0.131 Model20
## 5    24         14    0.00824 mae     standard    3.56     5   0.112 Model25</code></pre>
<p>Visualize the tuning results</p>
<pre class="r"><code>autoplot(xgboost_res)</code></pre>
<p><img src="2020-12-03_ConcreteXGB_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Select the best parameters based on the lowest mean absolute error.</p>
<pre class="r"><code>params_xgboost_best &lt;- xgboost_res %&gt;% select_best(&quot;mae&quot;)
params_xgboost_best</code></pre>
<pre><code>## # A tibble: 1 x 4
##   min_n tree_depth learn_rate .config
##   &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;  
## 1    18         10     0.0265 Model14</code></pre>
<p>Finalize workflow with the best model parameters</p>
<pre class="r"><code>final_xgboost &lt;- finalize_workflow(concrete_wf, params_xgboost_best)

final_xgboost</code></pre>
<pre><code>## == Workflow ==============================================================
## Preprocessor: Recipe
## Model: boost_tree()
## 
## -- Preprocessor ----------------------------------------------------------
## 2 Recipe Steps
## 
## * step_center()
## * step_scale()
## 
## -- Model -----------------------------------------------------------------
## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   trees = 1000
##   min_n = 18
##   tree_depth = 10
##   learn_rate = 0.0264752492619167
## 
## Engine-Specific Arguments:
##   objective = reg:squarederror
## 
## Computational engine: xgboost</code></pre>
<p>Which Features are most important?</p>
<pre class="r"><code>final_xgboost %&gt;%
  fit(data = concrete_train) %&gt;%
  pull_workflow_fit() %&gt;%
  vip(aesthetics = list(fill = &quot;steelblue&quot;)) +
  labs(title = &quot;XGBoost Model Importance - Compressive Strength (MPa) Prediction&quot;)</code></pre>
<pre><code>## Warning: `as.tibble()` is deprecated as of tibble 2.0.0.
## Please use `as_tibble()` instead.
## The signature and semantics have changed, see `?as_tibble`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p><img src="2020-12-03_ConcreteXGB_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="stage-3-train-final-model" class="section level3">
<h3>Stage 3: Train Final Model</h3>
<p>Fit model on train and evaluate on test.</p>
<pre class="r"><code>final_res &lt;- last_fit(final_xgboost, concrete_split, metrics = metric_set(rmse, rsq, mae))</code></pre>
<p>Assess final model performance metrics.</p>
<pre class="r"><code>collect_metrics(final_res)</code></pre>
<pre><code>## # A tibble: 3 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       3.67 
## 2 rsq     standard       0.951
## 3 mae     standard       2.57</code></pre>
<p>Visualize actual vs. predicted compressive strength for final model.</p>
<pre class="r"><code>collect_predictions(final_res) %&gt;%
  ggplot(aes(compressive_strength, .pred)) +
  geom_abline(slope = 1, lty = 2, color = &quot;gray50&quot;, alpha = 0.5) +
  geom_point(alpha = 0.6, color = &quot;midnightblue&quot;) +
  ylim(0, NA) +
  labs(title = &quot;XGBoost Model Performance for Concrete Dataset&quot;, 
       x = &quot;Actual Compressive Strength (MPa)&quot;, 
       y = &quot;Predicted Compressive Strength (MPa)&quot;)</code></pre>
<p><img src="2020-12-03_ConcreteXGB_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
</div>

<div id="rmd-source-code">---
output: 
  html_document:
    code_download: true
    includes:
      after_body: footer.html
---
<br>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(knitr)
library(readxl)
library(tidyverse)

#Tidymodels
library(tidymodels)
library(vip)
```

## **Extreme Gradient Boosting Modeling of the Concrete Compressive Strength Dataset**
*Posted on December 3, 2020*

In this post, we will begin to use machine learning techniques for predicting compressive strength of formulations using the concrete dataset.  In a previous post, we created a model using a conventional material modeling approach which resulted in an R^2^ of 0.78.  Here we will use an XGBoost model to predict compressive strength and compare the results with the conventional material model.

```{r, include=FALSE}
filename <- "Concrete_Data.xls"

folder <- "./data/"
numberCols <- 9 #total number of columns in spreadsheet

colTypes <- rep("numeric", numberCols)
concrete_tbl <- read_excel(path = paste0(folder, filename), col_types = colTypes)

concrete_tbl <- concrete_tbl %>%
  rename(cement = starts_with("Cement")) %>%
  rename(blast_furnace_slag = starts_with("Blast")) %>%
  rename(fly_ash = starts_with("Fly Ash")) %>%
  rename(water = starts_with("Water")) %>%
  rename(superplasticizer = starts_with("Super")) %>%
  rename(coarse_aggregate = starts_with("Coarse")) %>%
  rename(fine_aggregate = starts_with("Fine")) %>%
  rename(age = starts_with("Age")) %>%
  rename(compressive_strength = starts_with("Concrete"))
```

### Stage 1: Model Tuning

Initial splitting of the dataset into Training and Test Dataset  Here we use the rsample package to create an 80/20 split.  The concrete dataset contains 1030 formulations of which 825 are randomly assigned to training and 205 are randomly assigned to testing.
```{r}
set.seed(123)
concrete_split <- initial_split(concrete_tbl, prop = 0.80)
concrete_train <- training(concrete_split)
concrete_test <- testing(concrete_split)
```

Preprocessing is accomplished by using the recipe package.  The recipe provides the steps required to transform our raw data into a dataset suitable for machine learning.  The Concrete dataset actually doesn't require much reformatting.  The major issue was the lengthy column names which was addressed immediately after the dataset was imported.  The dataset contained all numerical values and no missing data.  Initially we will just center and scale the predictors before sending to the nnet model.
```{r}
concrete_rec <- recipe(compressive_strength ~ ., data = concrete_train) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())

concrete_rec
```

Cross validation folds are created in order to assess the performance of the model parameters.  Here we use 5-fold cross validation to create splits from our training dataset and also using the preprocessing pipeline specified above.
```{r}
set.seed(234)
concrete_folds <- vfold_cv(concrete_train, v = 5)

concrete_folds
```

Model specifications are created using the parsnip package.  Here we specify a boosted tree model using the XGBoost engine.  Notice that the min n, tree depth and learn rate parameters have been specified to be tuned.  

```{r}
xgboost_spec = boost_tree(
  mode = "regression",
  trees = 1000,
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune()
) %>%
  set_engine("xgboost", objective = "reg:squarederror") %>%
  set_mode("regression")

xgboost_spec
```

```{r}
set.seed(345)
xgboost_grid <- grid_max_entropy(min_n(), tree_depth(), learn_rate(), size = 30)

# xgboost_grid %>%
#   ggplot(aes(penalty, hidden_units)) +
#   geom_point(color = "steelblue", size = 3) +
#   scale_x_log10() +
#   theme_light() +
#   labs(title = "Max Entropy Grid", x = "Penalty (log scale)", y = "Hidden Units")

xgboost_grid
```

Define a workflow for the tuning process
```{r}
concrete_wf <- workflow() %>%
  add_recipe(concrete_rec) %>%
  add_model(xgboost_spec)
```

Hyperparameter tuning is now performed using the tune_grid() function from the tune package.  Here we specific the formula, model, resamples, grid and metrics.  The metrics come from the yardstick package. For regression problems, we can specify multiple metrics such as mae, mape, rmse and rsq into a metric_set().
```{r}
doParallel::registerDoParallel()

set.seed(456)

begin <- Sys.time()

xgboost_res <- tune_grid(
  concrete_wf,
  resamples = concrete_folds,
  grid = xgboost_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(save_pred = TRUE)
)

end1 <- Sys.time() - begin
```

### Stage 2: Compare and Select the Best Model

Identify the best hyperparameter values using the show_best() function.
```{r}
xgboost_res %>% show_best("mae", n = 5)
```

Visualize the tuning results
```{r}
autoplot(xgboost_res)
```

Select the best parameters based on the lowest mean absolute error.
```{r}
params_xgboost_best <- xgboost_res %>% select_best("mae")
params_xgboost_best
```

Finalize workflow with the best model parameters
```{r}
final_xgboost <- finalize_workflow(concrete_wf, params_xgboost_best)

final_xgboost
```

Which Features are most important?
```{r}
final_xgboost %>%
  fit(data = concrete_train) %>%
  pull_workflow_fit() %>%
  vip(aesthetics = list(fill = "steelblue")) +
  labs(title = "XGBoost Model Importance - Compressive Strength (MPa) Prediction")
```

### Stage 3: Train Final Model

Fit model on train and evaluate on test.
```{r}
final_res <- last_fit(final_xgboost, concrete_split, metrics = metric_set(rmse, rsq, mae))
```

Assess final model performance metrics.
```{r}
collect_metrics(final_res)
```

Visualize actual vs. predicted compressive strength for final model.
```{r}
collect_predictions(final_res) %>%
  ggplot(aes(compressive_strength, .pred)) +
  geom_abline(slope = 1, lty = 2, color = "gray50", alpha = 0.5) +
  geom_point(alpha = 0.6, color = "midnightblue") +
  ylim(0, NA) +
  labs(title = "XGBoost Model Performance for Concrete Dataset", 
       x = "Actual Compressive Strength (MPa)", 
       y = "Predicted Compressive Strength (MPa)")
```
</div>
&nbsp;
<hr />
<p style="text-align: center;"> A work by <a href="https://github.com/datadavidz/">datadavidz</a></p>
&nbsp;
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://datadavidz.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("2020-12-03_ConcreteXGB.Rmd");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
